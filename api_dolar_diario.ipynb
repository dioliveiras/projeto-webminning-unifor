{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2059741",
   "metadata": {},
   "source": [
    "# 💵 ETL de Cotações — Projeto Web Unifor ETL\n",
    "\n",
    "## 📊 Painel com os dados do Projeto:\n",
    "https://app.powerbi.com/view?r=eyJrIjoiZTQ1MTM2NDktNjYwNy00ZWVkLWJmZTQtY2E1NTZkOTg3YWIwIiwidCI6IjkzYzkzMDI3LTY2MjctNDA0My04MDI4LWFkYzQxN2M1MTg1NyJ9\n",
    "\n",
    "## 🎯 Objetivo\n",
    "Este notebook implementa a coleta diária da **cotação do dólar comercial (USD/BRL)** e de outros indicadores de mercado, realizando as etapas de **extração, transformação e carga (ETL)** em um banco analítico **DuckDB**.  \n",
    "O objetivo é consolidar uma série histórica diária de preços (abertura, fechamento, máxima e mínima), que poderá ser utilizada para análises econômicas e correlações com notícias coletadas em outras etapas do projeto.\n",
    "\n",
    "\n",
    "\n",
    "## 🌐 Fonte de Dados\n",
    "Os dados de cotação são obtidos de fontes públicas de mercado financeiro, utilizando **APIs e bibliotecas Python** de extração automatizada (como \"yfinance' ou 'requests').\n",
    "\n",
    "| Fonte | Descrição |\n",
    "|--------|------------|\n",
    "| **Yahoo Finance** | Cotações históricas do par 'USDBRL=X' (Dólar/Real) |\n",
    "| **Banco Central do Brasil (BACEN)** *(opcional)* | Dados de referência oficial do câmbio PTAX |\n",
    "\n",
    "As informações incluem variações diárias do dólar, que são estruturadas e persistidas localmente no banco DuckDB.\n",
    "\n",
    "\n",
    "\n",
    "## ⚙️ Estrutura do Pipeline\n",
    "\n",
    "1. **Coleta:**  \n",
    "   - Extração automatizada de cotações via API ('yfinance').  \n",
    "   - Período de coleta: últimos 6 meses até a data atual.  \n",
    "   - Criação do DataFrame com colunas OHLC (Open, High, Low, Close).\n",
    "\n",
    "2. **Transformação:**  \n",
    "   - Conversão de datas ('DatetimeIndex' → 'DATE').  \n",
    "   - Padronização de nomes de colunas ('abertura', 'fechamento', 'alta', 'baixa').  \n",
    "   - Cálculo de colunas derivadas (ex: 'tendencia', 'filtroperiodo').  \n",
    "   - Validação de dados ausentes e tipos corretos.\n",
    "\n",
    "3. **Carga:**  \n",
    "   - Salvamento dos dados no banco **DuckDB ('dados_dolar.duckdb')**.  \n",
    "   - Atualização incremental com base na chave primária 'data'.  \n",
    "   - Exportação adicional em '.csv' e '.parquet'.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Estrutura da Tabela 'dolar_diario'\n",
    "\n",
    "| Coluna | Tipo | Descrição |\n",
    "|--------|------|-----------|\n",
    "| 'data' | DATE | Data de referência da cotação |\n",
    "| 'abertura' | DOUBLE | Valor de abertura do dólar |\n",
    "| 'fechamento' | DOUBLE | Valor de fechamento do dólar |\n",
    "| 'alta' | DOUBLE | Valor máximo do dia |\n",
    "| 'baixa' | DOUBLE | Valor mínimo do dia |\n",
    "| 'tendencia' | TEXT | Indicador de alta/baixa baseado em variação diária |\n",
    "| 'filtroperiodo' | TEXT | Marcador auxiliar para filtros de período |\n",
    "| 'dataCarga' | TIMESTAMP | Data e hora da carga no banco |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧾 Logs e Monitoramento\n",
    "O notebook utiliza **logs estruturados** em console e arquivo ('logs/api_dolar_diario.log') para:\n",
    "- Registrar início e fim de cada etapa do ETL.  \n",
    "- Indicar contagem de registros coletados e duração da execução.  \n",
    "- Reportar erros de conexão, schema ou duplicação de dados.  \n",
    "\n",
    "Cada execução é registrada com timestamp, permitindo auditoria e acompanhamento histórico do pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Reprodutibilidade\n",
    "- Notebook executável de ponta a ponta, com dependências listadas em 'requirements.txt'.  \n",
    "- Banco analítico em **DuckDB**, atualizado incrementalmente.  \n",
    "- Saídas auxiliares exportadas em '.csv' para inspeção.  \n",
    "- Ambiente compatível com reexecução automatizada via 'papermill' ou 'nbconvert'.\n",
    "\n",
    "---\n",
    "\n",
    "📅 **Última atualização:** 25/10/2025  \n",
    "👨‍💻 **Autor:** ANDERSON DE OLIVEIRA SILVA — Projeto Web Unifor ETL (2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacb203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "import duckdb\n",
    "\n",
    "# opcional: instalar yfinance se necessário\n",
    "# !pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68db1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Helpers de LOG\n",
    "# ---------------------------\n",
    "def now():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "class Step:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.t0 = time.time()\n",
    "        print(f\"[{now()}] [{self.name}] INÍCIO\")\n",
    "    def ok(self, extra=\"OK\"):\n",
    "        dt = time.time() - self.t0\n",
    "        print(f\"[{now()}] [{self.name}] FIM — {extra} ({dt:.2f}s)\")\n",
    "    def fail(self, err):\n",
    "        dt = time.time() - self.t0\n",
    "        print(f\"[{now()}] [{self.name}] FALHA — {err} ({dt:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc7a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-25 20:01:05] [PTAX/BCB - Coleta] INÍCIO\n",
      "[2025-10-25 20:01:07] [PTAX] Registros brutos: 146\n",
      "[2025-10-25 20:01:07] [PTAX] Fechamentos diários: 145 | Janela: 2025-04-01 → 2025-10-24\n",
      "[2025-10-25 20:01:07] [PTAX/BCB - Coleta] FIM — OK (1.77s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1) PTAX (BCB) — fechamento diário\n",
    "# =============================================================================\n",
    "s = Step(\"PTAX/BCB - Coleta\")\n",
    "try:\n",
    "    ini = \"04-01-2025\"\n",
    "    fim = date.today().strftime(\"%m-%d-%Y\")\n",
    "    url = (\n",
    "      \"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/\"\n",
    "      f\"CotacaoDolarPeriodo(dataInicial=@ini,dataFinalCotacao=@fim)?\"\n",
    "      f\"@ini='{ini}'&@fim='{fim}'&$select=cotacaoCompra,dataHoraCotacao&$top=10000&$format=json\"\n",
    "    )\n",
    "\n",
    "    data = requests.get(url, timeout=30).json()[\"value\"]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # total bruto (todas as cotações do dia)\n",
    "    print(f\"[{now()}] [PTAX] Registros brutos: {len(df)}\")\n",
    "\n",
    "    # última cotação do dia (fechamento)\n",
    "    df[\"data\"] = pd.to_datetime(df[\"dataHoraCotacao\"]).dt.date\n",
    "    df_daily = df.sort_values(\"dataHoraCotacao\").groupby(\"data\").tail(1)\n",
    "    df_daily = df_daily[[\"data\",\"cotacaoCompra\"]].reset_index(drop=True)\n",
    "\n",
    "    # formata data para dd/mm/yyyy (exibição)\n",
    "    df_daily[\"data\"] = pd.to_datetime(df_daily[\"data\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # janela de datas (convertendo para comparar corretamente)\n",
    "    min_ptax = pd.to_datetime(df_daily[\"data\"], dayfirst=True).min().date()\n",
    "    max_ptax = pd.to_datetime(df_daily[\"data\"], dayfirst=True).max().date()\n",
    "    print(f\"[{now()}] [PTAX] Fechamentos diários: {len(df_daily)} | Janela: {min_ptax} → {max_ptax}\")\n",
    "\n",
    "    s.ok()\n",
    "except Exception as e:\n",
    "    s.fail(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae41950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-25 20:01:07] [PTAX/BCB - Carga DuckDB] INÍCIO\n",
      "[2025-10-25 20:01:07] [PTAX] Linhas na tabela dolar_diario: 145\n",
      "[2025-10-25 20:01:07] [PTAX] Export CSV -> ./exports/dolar_diario.csv\n",
      "[2025-10-25 20:01:07] [PTAX/BCB - Carga DuckDB] FIM — Carga concluída (0.06s)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2) PTAX — carga no DuckDB\n",
    "# =============================================================================\n",
    "s = Step(\"PTAX/BCB - Carga DuckDB\")\n",
    "try:\n",
    "    DB_PATH = \"dados_dolar.duckdb\"\n",
    "    con = duckdb.connect(DB_PATH)\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dolar_diario (\n",
    "      data DATE,\n",
    "      cotacao_compra DOUBLE\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    con.register(\"df_stage\", df_daily)\n",
    "    con.execute(\"\"\"\n",
    "    MERGE INTO dolar_diario AS t\n",
    "    USING (\n",
    "      SELECT\n",
    "        STRPTIME(data, '%d/%m/%Y')::DATE AS data,\n",
    "        CAST(cotacaoCompra AS DOUBLE)     AS cotacao_compra\n",
    "      FROM df_stage\n",
    "    ) AS s\n",
    "    ON t.data = s.data\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "      cotacao_compra = s.cotacao_compra\n",
    "    WHEN NOT MATCHED THEN INSERT (data, cotacao_compra)\n",
    "    VALUES (s.data, s.cotacao_compra);\n",
    "    \"\"\")\n",
    "\n",
    "    total_ptax_db = con.execute(\"SELECT COUNT(*) FROM dolar_diario;\").fetchone()[0]\n",
    "    print(f\"[{now()}] [PTAX] Linhas na tabela dolar_diario: {total_ptax_db}\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    COPY dolar_diario TO './exports/dolar_diario.csv' (HEADER, DELIMITER ',');\n",
    "    \"\"\")\n",
    "    print(f\"[{now()}] [PTAX] Export CSV -> ./exports/dolar_diario.csv\")\n",
    "\n",
    "    con.unregister(\"df_stage\")\n",
    "    con.close()\n",
    "    s.ok(\"Carga concluída\")\n",
    "except Exception as e:\n",
    "    s.fail(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21871154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-25 20:01:07] [Yahoo OHLC - Coleta] INÍCIO\n",
      "[2025-10-25 20:01:08] [YF] Linhas OHLC: 147 | Janela: 2025-04-01 → 2025-10-24\n",
      "[2025-10-25 20:01:08] [Yahoo OHLC - Coleta] FIM — OK (0.37s)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3) Yahoo Finance — OHLC diário USDBRL=X\n",
    "# =============================================================================\n",
    "s = Step(\"Yahoo OHLC - Coleta\")\n",
    "try:\n",
    "    ANO = date.today().year\n",
    "    inicio = pd.Timestamp(ANO, 4, 1)\n",
    "    fim_desejado = pd.Timestamp(ANO, 10, 31)\n",
    "    fim = min(fim_desejado, pd.Timestamp.today().normalize())\n",
    "\n",
    "    ticker = \"USDBRL=X\"\n",
    "\n",
    "    df_yf = yf.download(\n",
    "      ticker,\n",
    "      start=inicio,\n",
    "      end=fim + pd.Timedelta(days=1),  # inclui o último dia\n",
    "      interval=\"1d\",\n",
    "      auto_adjust=False,\n",
    "      progress=False,\n",
    "    )\n",
    "    if df_yf.empty:\n",
    "        raise SystemExit(\"Nenhum dado retornado pelo Yahoo Finance para o período.\")\n",
    "\n",
    "    ohlc = (\n",
    "      df_yf.reset_index()[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "        .rename(columns={\n",
    "          \"Date\": \"data\",\n",
    "          \"Open\": \"abertura\",\n",
    "          \"High\": \"alta\",\n",
    "          \"Low\": \"baixa\",\n",
    "          \"Close\": \"fechamento\",\n",
    "        })\n",
    "    )\n",
    "    ohlc[[\"abertura\",\"fechamento\",\"alta\",\"baixa\"]] = (\n",
    "      ohlc[[\"abertura\",\"fechamento\",\"alta\",\"baixa\"]].round(4)\n",
    "    )\n",
    "\n",
    "    min_ohlc = pd.to_datetime(ohlc[\"data\"]).min().date()\n",
    "    max_ohlc = pd.to_datetime(ohlc[\"data\"]).max().date()\n",
    "    print(f\"[{now()}] [YF] Linhas OHLC: {len(ohlc)} | Janela: {min_ohlc} → {max_ohlc}\")\n",
    "\n",
    "    s.ok()\n",
    "except Exception as e:\n",
    "    s.fail(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0866044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-25 20:01:08] [Yahoo OHLC - Carga DuckDB] INÍCIO\n",
      "Colunas pandas: ['data', 'abertura', 'alta', 'baixa', 'fechamento']\n",
      "[2025-10-25 20:01:08] [YF] Linhas na tabela dolar_ohlc: 147\n",
      "[2025-10-25 20:01:08] [YF] Export CSV -> ./exports/dolar_ohlc.csv\n",
      "[2025-10-25 20:01:08] [YF] Export CSV (via pandas) -> ./exports/dolar_ohlc_yahoo.csv\n",
      "[2025-10-25 20:01:08] [Yahoo OHLC - Carga DuckDB] FIM — Carga concluída (0.06s)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4) Yahoo OHLC — carga no DuckDB\n",
    "# =============================================================================\n",
    "s = Step(\"Yahoo OHLC - Carga DuckDB\")\n",
    "try:\n",
    "    DB_PATH = \"dados_dolar.duckdb\"\n",
    "    TABELA = \"dolar_ohlc\"\n",
    "    con = duckdb.connect(DB_PATH)\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TABELA} (\n",
    "     data DATE PRIMARY KEY,\n",
    "     abertura  DOUBLE,\n",
    "     fechamento DOUBLE,\n",
    "     alta    DOUBLE,\n",
    "     baixa   DOUBLE\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    # 1) Achatar colunas vindas do yfinance (MultiIndex -> string simples)\n",
    "    if isinstance(ohlc.columns, pd.MultiIndex):\n",
    "        ohlc.columns = ohlc.columns.get_level_values(0)\n",
    "\n",
    "    # 2) Garantir tipos\n",
    "    ohlc[\"data\"] = pd.to_datetime(ohlc[\"data\"]).dt.date  # vira datetime.date\n",
    "    for col in [\"abertura\", \"fechamento\", \"alta\", \"baixa\"]:\n",
    "        ohlc[col] = pd.to_numeric(ohlc[col], errors=\"coerce\")\n",
    "\n",
    "    print(\"Colunas pandas:\", list(ohlc.columns))  # ['data','abertura','fechamento','alta','baixa']\n",
    "\n",
    "    con.register(\"df_stage\", ohlc)\n",
    "    # UPSERT simples usando a PK(data)\n",
    "    \n",
    "    con.execute(f\"\"\"\n",
    "    INSERT OR REPLACE INTO {TABELA}\n",
    "    SELECT\n",
    "    CAST(\"data\" AS DATE)        AS data,\n",
    "    CAST(\"abertura\" AS DOUBLE)  AS abertura,\n",
    "    CAST(\"fechamento\" AS DOUBLE)AS fechamento,\n",
    "    CAST(\"alta\" AS DOUBLE)      AS alta,\n",
    "    CAST(\"baixa\" AS DOUBLE)     AS baixa\n",
    "    FROM df_stage;\n",
    "    \"\"\")\n",
    "\n",
    "    total_ohlc_db = con.execute(f\"SELECT COUNT(*) FROM {TABELA};\").fetchone()[0]\n",
    "    print(f\"[{now()}] [YF] Linhas na tabela {TABELA}: {total_ohlc_db}\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    COPY dolar_ohlc TO './exports/dolar_ohlc.csv' (HEADER, DELIMITER ',');\n",
    "    \"\"\")\n",
    "    print(f\"[{now()}] [YF] Export CSV -> ./exports/dolar_ohlc.csv\")\n",
    "\n",
    "    con.unregister(\"df_stage\")\n",
    "    con.close()\n",
    "\n",
    "    # também exporta o DF direto (útil pra auditoria)\n",
    "    ohlc.to_csv('./exports/dolar_ohlc_yahoo.csv', index=False)\n",
    "    print(f\"[{now()}] [YF] Export CSV (via pandas) -> ./exports/dolar_ohlc_yahoo.csv\")\n",
    "\n",
    "    s.ok(\"Carga concluída\")\n",
    "except Exception as e:\n",
    "    s.fail(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "688db338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo – Séries (PTAX & Yahoo)\n",
      "--------------------------------\n",
      "[2025-10-25 20:01:08] PTAX diário: 145 | Janela: 2025-04-01 → 2025-10-24\n",
      "[2025-10-25 20:01:08] OHLC linhas: 147 | Janela: 2025-04-01 → 2025-10-24\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5) Resumo final (logs de status + contagens)\n",
    "# =============================================================================\n",
    "print(\"\\nResumo – Séries (PTAX & Yahoo)\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"[{now()}] PTAX diário: {len(df_daily)} | Janela: {min_ptax} → {max_ptax}\")\n",
    "print(f\"[{now()}] OHLC linhas: {len(ohlc)} | Janela: {min_ohlc} → {max_ohlc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
